# ğŸ”§ ConfiguraÃ§Ã£o do OpenAI Vision (GPT-4o)

O **Modo Live do Theo** agora usa **OpenAI GPT-4o** com visÃ£o em tempo real para anÃ¡lise multimodal.

## ğŸ“‹ Por que OpenAI?

âœ… **Melhor compatibilidade**: API mais estÃ¡vel e confiÃ¡vel  
âœ… **Melhor qualidade**: GPT-4o tem excelente compreensÃ£o visual  
âœ… **JÃ¡ configurado**: VocÃª jÃ¡ tem `OPENAI_API_KEY` para Whisper e TTS  
âœ… **Mesma API**: Usa a mesma key para tudo (STT, TTS, Vision, Chat)

## ğŸ¯ O que o GPT-4o faz no Modo Live?

- **VisÃ£o em Tempo Real**: Analisa 4 frames de vÃ­deo dos Ãºltimos 2 segundos
- **Leitura de Documentos**: LÃª laudos mÃ©dicos, certidÃµes, documentos
- **CompreensÃ£o Contextual**: Entende fala + contexto visual simultaneamente
- **Alta ResoluÃ§Ã£o**: Modo `detail: "high"` para OCR preciso

## âœ… JÃ¡ Configurado!

Se vocÃª jÃ¡ tem transcriÃ§Ã£o de Ã¡udio funcionando, **o Vision jÃ¡ estÃ¡ pronto!**

A mesma `OPENAI_API_KEY` Ã© usada para:
- âœ… Whisper (transcriÃ§Ã£o de Ã¡udio)
- âœ… TTS-HD (voz do Theo)
- âœ… GPT-4o Vision (anÃ¡lise visual)
- âœ… Chat (fallback se vision falhar)

## ğŸš€ Como Testar

1. Abra http://localhost:3000
2. Clique em **"Modo Live"** na sidebar
3. Permita acesso Ã  **webcam** e **microfone**
4. Segure o botÃ£o **"Segurar para Falar"**
5. Mostre um documento (ex: laudo, certidÃ£o)
6. Fale: _"O que vocÃª vÃª neste documento?"_
7. Solte o botÃ£o
8. âœ¨ **Theo vai descrever o que vÃª e ler informaÃ§Ãµes!**

## ğŸ“Š Exemplos de Uso

### ValidaÃ§Ã£o de Documentos
```
VocÃª: "Este laudo estÃ¡ completo?"
[mostra laudo mÃ©dico na cÃ¢mera]

Theo: "Vejo que vocÃª estÃ¡ mostrando um laudo mÃ©dico. 
Consigo identificar um CID (F84.0 - Autismo), 
data de emissÃ£o e carimbo mÃ©dico. Para o BPC/LOAS, 
este laudo estÃ¡ adequado!"
```

### IdentificaÃ§Ã£o de BenefÃ­cios
```
VocÃª: "Com este documento, que benefÃ­cios posso pedir?"
[mostra certidÃ£o de nascimento com anotaÃ§Ãµes]

Theo: "Vejo uma certidÃ£o de nascimento. Com ela e um 
laudo mÃ©dico atualizado, vocÃª pode solicitar: BPC/LOAS, 
Passe Livre, IsenÃ§Ã£o de IPVA..."
```

### OrientaÃ§Ã£o de Preenchimento
```
VocÃª: "Como preencho este formulÃ¡rio?"
[mostra formulÃ¡rio do INSS]

Theo: "Vejo o formulÃ¡rio de requerimento do BPC. 
Na seÃ§Ã£o que estÃ¡ em branco, vocÃª deve preencher..."
```

## ğŸ”§ Troubleshooting

### âŒ Erro: "OpenAI API key nÃ£o configurada"
**SoluÃ§Ã£o**: Adicione no `.env.local`:
```bash
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxx
```

### âŒ Vision nÃ£o estÃ¡ funcionando, mas chat sim
**Verificar**:
1. Webcam estÃ¡ ativa? (Ã­cone "CÃ‚MERA ATIVA" deve aparecer)
2. Frames estÃ£o sendo capturados? (console.log no navegador)
3. Fallback automÃ¡tico para chat normal estÃ¡ ativo

### âŒ "Invalid format" no Whisper
**SoluÃ§Ã£o**: Problema de formato de Ã¡udio. Verifique:
- Chrome/Edge: devem usar `audio/mp4`
- Firefox: pode usar `audio/webm`

## ğŸ’° Custos

### GPT-4o Vision
- **Entrada**: $2.50 / 1M tokens (~$0.0025 por request)
- **Imagens**: ~170 tokens por frame em alta resoluÃ§Ã£o
- **Request tÃ­pico**: 4 frames + texto = ~1000 tokens = $0.0025

### Para hackathon
- ~$0.50-1.00 para centenas de testes
- Muito acessÃ­vel para MVP/demo

## ğŸ›ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Ajustar qualidade de imagem
Em `app/api/openai-multimodal/route.ts`:
```typescript
detail: "high" // Melhor OCR (atual)
detail: "low"  // Mais rÃ¡pido, menor custo
```

### Ajustar nÃºmero de frames
Em `lib/use-openai-live-conversation.ts`:
```typescript
images: videoFrames.slice(-4) // 4 frames (atual)
images: videoFrames.slice(-2) // 2 frames (mais rÃ¡pido)
images: videoFrames.slice(-6) // 6 frames (mais contexto)
```

### Trocar modelo
Em `app/api/openai-multimodal/route.ts`:
```typescript
model: "gpt-4o"              // Melhor (atual)
model: "gpt-4-turbo"         // Alternativa mais barata
model: "gpt-4-vision-preview" // VersÃ£o antiga
```

## ğŸ“š ReferÃªncias

- OpenAI Vision: https://platform.openai.com/docs/guides/vision
- GPT-4o: https://openai.com/index/hello-gpt-4o/
- Pricing: https://openai.com/api/pricing/

